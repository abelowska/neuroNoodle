{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccede655-3da6-4f48-b88b-85c6bfd7ffd2",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4c035c-33a2-4ffb-96a3-29957a30addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from brainvision import read_raw_brainvision as read_raw_brainvision_local\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unified_events_dict = {\n",
    "    'Stimulus/ 3-B-NOSTOP-L': 1,\n",
    "    'Stimulus/ 3-B-NOSTOP-R': 2,\n",
    "    \n",
    "    'Stimulus/ 3-B-STOP1-SE-L': 3,\n",
    "    'Stimulus/ 3-B-STOP1-SE-R': 4,\n",
    "    'Stimulus/ 3-B-STOP1-SS-L': 5,\n",
    "    'Stimulus/ 3-B-STOP1-SS-R': 6,\n",
    "    \n",
    "    'Stimulus/ 3-B-STOP2-SE-L': 7,\n",
    "    'Stimulus/ 3-B-STOP2-SE-R': 8,\n",
    "    'Stimulus/ 3-B-STOP2-SS-L': 9,\n",
    "    'Stimulus/ 3-B-STOP2-SS-R': 10,\n",
    "    \n",
    "    'Stimulus/ 3-B-STOP3-SE-L': 11,\n",
    "    'Stimulus/ 3-B-STOP3-SE-R': 12,\n",
    "    'Stimulus/ 3-B-STOP3-SS-L': 13,\n",
    "    'Stimulus/ 3-B-STOP3-SS-R': 14,\n",
    "\n",
    "    'Stimulus/ 3-B-STOP4-SE-L': 15,\n",
    "    'Stimulus/ 3-B-STOP4-SE-R': 16,\n",
    "    'Stimulus/ 3-B-STOP4-SS-L': 17,\n",
    "    'Stimulus/ 3-B-STOP4-SS-R': 18,\n",
    "\n",
    "    'Stimulus/ 3-B-STOP5-SE-L': 19,\n",
    "    'Stimulus/ 3-B-STOP5-SE-R': 20,\n",
    "    'Stimulus/ 3-B-STOP5-SS-L': 21,\n",
    "    'Stimulus/ 3-B-STOP5-SS-R': 22,\n",
    "\n",
    "    'Stimulus/ 3-B-STOP6-SE-L': 23,\n",
    "    'Stimulus/ 3-B-STOP6-SE-R': 24,\n",
    "    'Stimulus/ 3-B-STOP6-SS-L': 25,\n",
    "    'Stimulus/ 3-B-STOP6-SS-R': 26,\n",
    "\n",
    "    'Stimulus/ 3-B-STOP7-SE-L': 27,\n",
    "    'Stimulus/ 3-B-STOP7-SE-R': 28,\n",
    "    'Stimulus/ 3-B-STOP7-SS-L': 29,\n",
    "    'Stimulus/ 3-B-STOP7-SS-R': 30,   \n",
    "    \n",
    "    'Stimulus/ 3-R-B-NOSTOP-L': 31,\n",
    "    'Stimulus/ 3-R-B-NOSTOP-R': 32,\n",
    "    \n",
    "    'Stimulus/ 3-R-B-STOP1-SE-L': 33,\n",
    "    'Stimulus/ 3-R-B-STOP1-SE-R': 34,\n",
    "\n",
    "    'Stimulus/ 3-R-B-STOP2-SE-L': 35,\n",
    "    'Stimulus/ 3-R-B-STOP2-SE-R': 36,\n",
    "\n",
    "    'Stimulus/ 3-R-B-STOP3-SE-L': 37,\n",
    "    'Stimulus/ 3-R-B-STOP3-SE-R': 38,\n",
    "\n",
    "    'Stimulus/ 3-R-B-STOP4-SE-L': 39,\n",
    "    'Stimulus/ 3-R-B-STOP4-SE-R': 40,\n",
    "\n",
    "    'Stimulus/ 3-R-B-STOP5-SE-L': 41,\n",
    "    'Stimulus/ 3-R-B-STOP5-SE-R': 42,\n",
    "\n",
    "    'Stimulus/ 3-R-B-STOP6-SE-L': 43,\n",
    "    'Stimulus/ 3-R-B-STOP6-SE-R': 44,\n",
    "\n",
    "    'Stimulus/ 3-R-B-STOP7-SE-L': 45,\n",
    "    'Stimulus/ 3-R-B-STOP7-SE-R': 46,\n",
    "\n",
    "    'Stimulus/ 3-STOP1-SE-L': 47,\n",
    "    'Stimulus/ 3-STOP1-SE-R': 48,\n",
    "    'Stimulus/ 3-STOP1-SS-L': 49,\n",
    "    'Stimulus/ 3-STOP1-SS-R': 50,\n",
    "\n",
    "    'Stimulus/ 3-STOP2-SE-L': 51,\n",
    "    'Stimulus/ 3-STOP2-SE-R': 52,\n",
    "    'Stimulus/ 3-STOP2-SS-L': 53,\n",
    "    'Stimulus/ 3-STOP2-SS-R': 54,\n",
    "\n",
    "    'Stimulus/ 3-STOP3-SE-L': 55,\n",
    "    'Stimulus/ 3-STOP3-SE-R': 56,\n",
    "    'Stimulus/ 3-STOP3-SS-L': 57,\n",
    "    'Stimulus/ 3-STOP3-SS-R': 58,\n",
    "\n",
    "    'Stimulus/ 3-STOP4-SE-L': 59,\n",
    "    'Stimulus/ 3-STOP4-SE-R': 60,\n",
    "    'Stimulus/ 3-STOP4-SS-L': 61,\n",
    "    'Stimulus/ 3-STOP4-SS-R': 62,\n",
    "\n",
    "    'Stimulus/ 3-STOP5-SE-L': 63,\n",
    "    'Stimulus/ 3-STOP5-SE-R': 64,\n",
    "    'Stimulus/ 3-STOP5-SS-L': 65,\n",
    "    'Stimulus/ 3-STOP5-SS-R': 66,\n",
    "\n",
    "    'Stimulus/ 3-STOP6-SE-L': 67,\n",
    "    'Stimulus/ 3-STOP6-SE-R': 68,\n",
    "    'Stimulus/ 3-STOP6-SS-L': 69,\n",
    "    'Stimulus/ 3-STOP6-SS-R': 70,\n",
    "\n",
    "    'Stimulus/ 3-STOP7-SE-L': 71,\n",
    "    'Stimulus/ 3-STOP7-SE-R': 72,\n",
    "    'Stimulus/ 3-STOP7-SS-L': 73,\n",
    "    'Stimulus/ 3-STOP7-SS-R': 74,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a45b78c551bef95"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e76716-0838-42bd-b77a-29cd15051c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unnecessary_events(raw, events_names = ['Time 0/', 'New Segment/']):\n",
    "    events_to_remove = []\n",
    "    events, events_id = mne.events_from_annotations(raw)\n",
    "\n",
    "    for event_name in events_names:\n",
    "        events_to_remove.append(events_id[event_name])\n",
    "    \n",
    "    # Filter out the unwanted events\n",
    "    filtered_events = np.array([event.tolist() for event in events if event[2] not in events_to_remove])\n",
    "    filtered_event_id = {key: value for key, value in events_id.items() if value not in events_to_remove}\n",
    "    \n",
    "    new_event_desc = {value:str(key) for key, value in filtered_event_id.items()}\n",
    "    \n",
    "    # Use mne.annotations_from_events to create new annotations\n",
    "    new_annotations = mne.annotations_from_events(filtered_events, sfreq=raw.info['sfreq'], event_desc=new_event_desc)\n",
    "    \n",
    "    # Set new annotations to raw data\n",
    "    raw_copy = raw.copy().set_annotations(new_annotations)\n",
    "\n",
    "    return raw_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb1c35c5-0284-4e76-b38e-5a3681784841"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dir = '../data/sst_old'\n",
    "filename = 'AD1406_SST14_Artif Rej 75'\n",
    "filename2 = 'AB2407_SST14_new_Artif Rej 75'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da6236ce4f104267"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc23e6cd-a753-4243-a7b9-036aa4e131f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = read_raw_brainvision_local(f'{dir}/{filename}.vhdr', preload=True)\n",
    "sampling_rate = raw.info['sfreq']\n",
    "print(raw.get_data().shape)\n",
    "raw2 = read_raw_brainvision_local(f'{dir}/{filename2}.vhdr', preload=True)\n",
    "print(raw2.get_data().shape)\n",
    "\n",
    "raw_concatenated = mne.concatenate_raws([raw, raw2])\n",
    "print(raw_concatenated.get_data().shape)\n",
    "events, event_id = mne.events_from_annotations(raw_concatenated, unified_events_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = raw.plot(duration=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bafd04e5a947a53e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ef346-e1a2-4947-9c47-aa395dcb43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping function using regular expressions\n",
    "def map_event(event):\n",
    "    # Patterns for matching\n",
    "    patterns = {\n",
    "        r'^Stimulus/ 3-B-NOSTOP.*': 'go/nostop',\n",
    "        r'^Stimulus/ 3-B-STOP(\\d+).*': lambda m: f'go/stop/{m.group(1)}',\n",
    "        r'^Stimulus/ 3-R-B-NOSTOP.*': 'response/no-stop_correct',\n",
    "        r'^Stimulus/ 3-R-B-STOP(\\d+).*': lambda m: f'response/incorrect/{m.group(1)}',\n",
    "        r'^Stimulus/ 3-STOP(\\d+).*': lambda m: f'stop/{m.group(1)}'\n",
    "    }\t\n",
    "    # Check each pattern\n",
    "    for pattern, replacement in patterns.items():\n",
    "        match = re.fullmatch(pattern, event)\n",
    "        if match:\n",
    "            return replacement if not callable(replacement) else replacement(match)\n",
    "    # Default return value if no pattern matches\n",
    "    return 'unknown'\n",
    "\n",
    "# Define the function to categorize events into 'go', 'response', or 'stop'\n",
    "def categorize_type(event_general):\n",
    "    if 'go' in event_general:\n",
    "        return 'go'\n",
    "    elif 'response/no-stop_correct' in event_general:\n",
    "        return 'response_nostop'\n",
    "    elif 'response' in event_general:\n",
    "        return 'response'\n",
    "    elif 'stop' in event_general:\n",
    "        return 'stop'\n",
    "    return 'unknown'\n",
    "\n",
    "# Define the SSD mapping\n",
    "ssd_mapping = {\n",
    "    1: 100,\n",
    "    2: 150,\n",
    "    3: 200,\n",
    "    4: 250,\n",
    "    5: 300,\n",
    "    6: 350,\n",
    "    7: 400\n",
    "}\n",
    "\n",
    "# Define the function to map to SSD values\n",
    "def map_ssd(event_general):\n",
    "    \"\"\"\n",
    "    Map SSD based on the event string.\n",
    "\n",
    "    Parameters:\n",
    "    event_general (str): The event string.\n",
    "\n",
    "    Returns:\n",
    "    float: The mapped SSD value or np.nan if not found.\n",
    "    \"\"\"\n",
    "    # Define the patterns to match\n",
    "    patterns = [\n",
    "        r'go/stop/(\\d+)',\n",
    "        r'stop/(\\d+)',\n",
    "        r'response/incorrect/(\\d+)'\n",
    "    ]\n",
    "\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, event_general)\n",
    "        if match:\n",
    "            number = int(match.group(1))\n",
    "            return ssd_mapping.get(number, np.nan)  # Use np.nan for missing values\n",
    "\n",
    "    return np.nan\n",
    "\n",
    "def add_sri(df, sampling_rate=64):\n",
    "    \"\"\"\n",
    "    Add the SRI column to the DataFrame, which represents the distance \n",
    "    between stop events and response/incorrect events in terms of latency \n",
    "    multiplied by the sampling rate.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing events with 'event' and 'latency' columns.\n",
    "    sampling_rate (float): The sampling rate to convert latency differences to time.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with an additional 'sri' column.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the sri column with np.nan\n",
    "    df['sri'] = np.nan\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # Iterate through the DataFrame to calculate the sri values\n",
    "    for idx, row in df.iterrows():\n",
    "        if 'response/incorrect' in row['event_general']:\n",
    "            stop_idx = idx-1\n",
    "            if stop_idx > 0:\n",
    "                if 'stop' in df.loc[stop_idx]['event_general']:\n",
    "                    distance = (row['latency'] - df.loc[stop_idx, 'latency']) / sampling_rate * 1000\n",
    "                    df.at[idx, 'sri'] = distance\n",
    "                else:\n",
    "                    print('ERROR - no stop above error incorrect')\n",
    "            else:\n",
    "                print('STOP idx at 0')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac6547e-8fcb-4ae7-957a-231b7fa1e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = pd.DataFrame(events, columns=['latency', 'duration', 'id'])\n",
    "\n",
    "# Invert the dictionary to map IDs to event names\n",
    "id_to_event = {value: key for key, value in event_id.items()}\n",
    "\n",
    "# Create a new 'event' column by mapping 'id' to event names\n",
    "events_df['event'] = events_df['id'].map(id_to_event)\n",
    "events_df['event_general'] = events_df['event'].apply(map_event)\n",
    "events_df['type'] = events_df['event_general'].apply(categorize_type)\n",
    "events_df['ssd'] = events_df['event_general'].apply(map_ssd)\n",
    "events_df['response_type'] = events_df['event_general'].str.extract(r'response/(correct|incorrect)', expand=False)\n",
    "events_df['response_type'] = events_df['response_type'].fillna('n-a')\n",
    "\n",
    "events_df = add_sri(events_df, sampling_rate=sampling_rate)\n",
    "\n",
    "ssd_mean = np.nanmean(events_df['ssd'])\n",
    "events_df['ssd_centered'] = events_df['ssd'] - ssd_mean\n",
    "events_df['ssd_normalized'] = events_df['ssd_centered'] / np.nanstd(events_df['ssd_centered'])\n",
    "\n",
    "sri_mean = np.nanmean(events_df['sri'])\n",
    "events_df['sri_centered'] = events_df['sri'] - sri_mean\n",
    "events_df['sri_normalized'] = events_df['sri_centered'] / np.nanstd(events_df['sri_centered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "events_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8a018e22ea0604d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check number of GO trials"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c2eacb2c1b22a78"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925c658-050b-4d6f-b028-a52c07481f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events_df[events_df['type'] == 'go'].shape)\n",
    "\n",
    "# save list of events\n",
    "# events_df.to_csv(f'{filename}_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8030b262-9bf5-43e0-b613-d0a753eda754",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_incorrect_df = events_df[events_df['event_general'].str.contains('response/incorrect/')]\n",
    "ssd = events_incorrect_df['ssd'].to_numpy()\n",
    "sri = events_incorrect_df['sri'].to_numpy()\n",
    "\n",
    "print(f'Correlation between SSD and SRI: {pearsonr(ssd, sri)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d57677c-d4e1-44c7-aae8-adc52ccf5298",
   "metadata": {},
   "source": [
    "---\n",
    "## Unfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdcc993-68cd-481e-9657-dda57748feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Julia package manager\n",
    "from juliacall import Pkg as jlPkg\n",
    "\n",
    "# Activate the environment in the current folder\n",
    "jlPkg.activate(\".\")\n",
    "\n",
    "# Check the status of the environment/installed packages -> will be empty at the beginning\n",
    "print(jlPkg.status())\n",
    "\n",
    "# Install Julia packages\n",
    "jlPkg.add(\"Unfold\")\n",
    "jlPkg.add(\"DataFrames\")\n",
    "jlPkg.add(url=\"https://github.com/unfoldtoolbox/UnfoldDecode.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from juliacall import Main as jl\n",
    "\n",
    "# The function seval() can be used to evaluate a piece of Julia code given as a string\n",
    "jl.seval(\"using DataFrames\")\n",
    "jl.seval(\"using Unfold\")\n",
    "jl.seval(\"using UnfoldDecode\")\n",
    "Unfold = jl.Unfold\n",
    "UnfoldDecode = jl.UnfoldDecode"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c87c3bc8a31c8db6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a6ea8654eeba5a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = raw.get_data()\n",
    "print(raw.info['sfreq'])\n",
    "print(data.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "75b9ed9051c36c6f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# events_df_no_nans = events_df.copy()\n",
    "# events_df_no_nans['ssd_centered'] = events_df_no_nans['ssd_centered'].fillna(0)\n",
    "# events_df_no_nans"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbc6925218fbcf53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Specify model formula\n",
    "bf_go = jl.seval(\"bf_go = firbasis(τ = (-0.2, 0.5), sfreq = 64)\")\n",
    "bf_stop= jl.seval(\"bf_stop = firbasis(τ = (-0.2, 0.5), sfreq = 64)\")\n",
    "bf_response = jl.seval(\"bf_response = firbasis(τ = (-0.1, 0.5), sfreq = 64)\")\n",
    "bf_response_nostop = jl.seval(\"bf_response_nostop = firbasis(τ = (-0.1, 0.5), sfreq = 64)\")\n",
    "\n",
    "\n",
    "formula_go = jl.seval(\"f_go = @formula 0 ~ 1\")\n",
    "formula_stop = jl.seval(\"f_stop = @formula 0 ~ 1 + ssd_centered\")\n",
    "formula_res = jl.seval(\"f_res = @formula 0 ~ 1 + ssd_centered + sri_centered\")\n",
    "formula_res_nostop = jl.seval(\"f_res_nostop = @formula 0 ~ 1\")\n",
    "\n",
    "bfDict = jl.seval(\"[ \\\"go\\\" => (f_go, bf_go), \\\"stop\\\" => (f_stop, bf_stop),  \\\"response\\\" => (f_res, bf_response), \\\"response_nostop\\\" => (f_res_nostop, bf_response_nostop)]\")\n",
    "\n",
    "# Convert the Python columns to Julia arrays\n",
    "type_column = jl.seval(\"Vector{String}\")(events_df['type'].tolist())\n",
    "response_type_column = jl.seval(\"Vector{String}\")(events_df['response_type'].tolist())\n",
    "ssd_centered_column = jl.seval(\"Vector{Float64}\")(events_df['ssd_normalized'].tolist())\n",
    "sri_centered_column = jl.seval(\"Vector{Float64}\")(events_df['sri_normalized'].tolist())\n",
    "latency_column = jl.seval(\"Vector{Int64}\")(events_df['latency'].tolist())\n",
    "\n",
    "# Create the Julia DataFrame\n",
    "events_df_jl = jl.DataFrame(\n",
    "    type=type_column,\n",
    "    latency=latency_column,\n",
    "    ssd_centered=ssd_centered_column,\n",
    "    sri_centered=sri_centered_column,\n",
    "    response_type=response_type_column\n",
    ")\n",
    "\n",
    "# Fit Unfold model\n",
    "m = Unfold.fit(\n",
    "    Unfold.UnfoldModel,\n",
    "    bfDict,\n",
    "    events_df_jl,\n",
    "    data,\n",
    "    # solver = jl.seval(\"(x, y) -> Unfold.solver_default(x, y; stderror = true)\"),\n",
    "    eventcolumn = \"type\",\n",
    ")\n",
    "\n",
    "# model_matrix = Unfold.modelmatrix(m)\n",
    "# design_matrix = Unfold.designmatrix(m)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57df3defbdb4b981"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pd.DataFrame(model_matrix.to_numpy()).to_csv('design_matrix.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e4c71b7edb4f095"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def jl_results_to_python(results_jl):\n",
    "    results_py_df = pd.DataFrame({\n",
    "        'channel': results_jl.channel,\n",
    "        'coefname': results_jl.coefname,\n",
    "        'estimate': results_jl.estimate,\n",
    "        'eventname': results_jl.eventname,\n",
    "        'group': results_jl.group,\n",
    "        'stderror': results_jl.stderror,\n",
    "        'time': results_jl.time\n",
    "    })\n",
    "    return results_py_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e596b2e2d38a0ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_jl = Unfold.coeftable(m)\n",
    "results_py = jl_results_to_python(results_jl)\n",
    "results_py"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d28e36d5a90f4f76"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e651c18afe7c0ae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Extract the coefficients for one channel\n",
    "results_channel = results_py[results_py.channel == 1]\n",
    "\n",
    "results_go = results_channel[results_channel.eventname == 'go']\n",
    "results_stop = results_channel[results_channel.eventname == 'stop']\n",
    "results_response = results_channel[results_channel.eventname == 'response']\n",
    "results_response_nostop = results_channel[results_channel.eventname == 'response_nostop']\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Set global font size for various elements\n",
    "plt.rcParams.update({\n",
    "    'font.size': 25,\n",
    "    'axes.titlesize': 30,\n",
    "    'axes.labelsize': 30,\n",
    "    'xtick.labelsize': 30,\n",
    "    'ytick.labelsize': 30,\n",
    "    'legend.fontsize': 25,\n",
    "    'figure.titlesize': 25,\n",
    "})\n",
    "linewidth = 5\n",
    "# Plot the coefficient estimates over time\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(30, 20), sharey=True)\n",
    "\n",
    "ax1 = sns.lineplot(\n",
    "    x = results_go.time,\n",
    "    y=results_go.estimate,\n",
    "    hue=results_go.coefname,\n",
    "    ax=ax1,\n",
    "    linewidth=linewidth\n",
    ")\n",
    "ax1.set(xlabel='Time [s]', ylabel='Coefficient estimate', title='Go')\n",
    "\n",
    "ax2 = sns.lineplot(\n",
    "    x = results_stop.time,\n",
    "    y=results_stop.estimate,\n",
    "    hue=results_stop.coefname,\n",
    "    ax=ax2,\n",
    "    linewidth=linewidth\n",
    ")\n",
    "ax2.set(xlabel='Time [s]', ylabel='Coefficient estimate', title='Stop')\n",
    "\n",
    "ax3 = sns.lineplot(\n",
    "    x = results_response.time,\n",
    "    y=results_response.estimate,\n",
    "    hue=results_response.coefname,\n",
    "    ax=ax3,\n",
    "    linewidth=linewidth\n",
    ")\n",
    "ax3.set(xlabel='Time [s]', ylabel='Coefficient estimate', title='Response')\n",
    "\n",
    "ax4 = sns.lineplot(\n",
    "    x = results_response_nostop.time,\n",
    "    y=results_response_nostop.estimate,\n",
    "    hue=results_response_nostop.coefname,\n",
    "    ax=ax4,\n",
    "    linewidth=linewidth\n",
    ")\n",
    "ax4.set(xlabel='Time [s]', ylabel='Coefficient estimate', title='Response nostop')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b43c8b1e7a82900c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5cab93f5491eea20"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Extract the coefficients for one channel\n",
    "# results_channel = results_py[results_py.channel == 1]\n",
    "# \n",
    "# results_go = results_channel[results_channel.eventname == 'go']\n",
    "# results_stop = results_channel[results_channel.eventname == 'stop']\n",
    "# results_response = results_channel[results_channel.eventname == 'response']\n",
    "# \n",
    "# \n",
    "# # Plot the coefficient estimates over time\n",
    "# fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "# \n",
    "# ax1 = sns.lineplot(\n",
    "#     x = results_go.time,\n",
    "#     y=results_go.estimate,\n",
    "#     hue=results_go.eventname,\n",
    "#     ax=ax1\n",
    "# )\n",
    "# ax1.set(xlabel='Time [s]', ylabel='Coefficient estimate', title='Go')\n",
    "# \n",
    "# ax2 = sns.lineplot(\n",
    "#     x = results_stop.time,\n",
    "#     y=results_stop.estimate,\n",
    "#     hue=results_stop.eventname,\n",
    "#     ax=ax2\n",
    "# )\n",
    "# ax2.set(xlabel='Time [s]', ylabel='Coefficient estimate', title='Stop')\n",
    "# \n",
    "# ax3 = sns.lineplot(\n",
    "#     x = results_response.time,\n",
    "#     y=results_response.estimate,\n",
    "#     hue=results_response.coefname,\n",
    "#     ax=ax3\n",
    "# )\n",
    "# ax3.set(xlabel='Time [s]', ylabel='Coefficient estimate', title='Response')\n",
    "# \n",
    "# \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6efc46a4cd7924b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroNoodle",
   "language": "python",
   "name": "neuronoodle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
