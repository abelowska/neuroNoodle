{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Simulation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f078782fc29645d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e66ba9e1bb9d44d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from simulations import simulate_erp_components_with_conditions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d18e0df38d29ca0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Config"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "407f2baa9d985cf3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = {\n",
    "    'go_intercept': 0.2,\n",
    "    'stop_intercept': 0.5,\n",
    "    'response_intercept':\n",
    "        {\n",
    "            'error': 0.7,\n",
    "            'correct_nostop':0.2\n",
    "        },\n",
    "    'interactions': {\n",
    "        'stop x SSD': True,\n",
    "        'response_error x SSD': True,\n",
    "        'response_error x SRI': True,\n",
    "    },\n",
    "    'probability': {\n",
    "        'stop': 0.3,\n",
    "        'error': 0.5,\n",
    "\n",
    "    },\n",
    "    'sri': {'loc': 0.2, 'scale': 0.05}\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "n_trials_per_ssd = 1000 \n",
    "distances_C_A = np.arange(0.1, 0.4, 0.05)\n",
    "sampling_rate = 64  \n",
    "noise_level = 0.3\n",
    "duration=1.5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c5bd37b5cbe1045"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Simulate ERP components with conditions\n",
    "erp_trials, data_df = simulate_erp_components_with_conditions(\n",
    "    n_trials_per_ssd, \n",
    "    distances_C_A,\n",
    "    config,\n",
    "    sampling_rate, \n",
    "    noise_level,\n",
    "    duration=duration,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a8a79edb7ec4915"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b5f9f523f81f3d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23ddf256830110f8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_nostop = data_df[data_df['response_type'] == 'nostop_correct']['signal'].to_numpy().mean(axis=0)\n",
    "x_error = data_df[data_df['response_type'] == 'error']['signal'].to_numpy().mean(axis=0)\n",
    "x_correct = data_df[data_df['response_type'] == 'correct']['signal'].to_numpy().mean(axis=0)\n",
    "\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "\n",
    "plt.plot(x_nostop, label = 'GO/NOSTOP')\n",
    "plt.plot(x_error, label = 'GO/STOP/SU')\n",
    "plt.plot(x_correct, label = 'GO/STOP/SS')\n",
    "\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Simulated ERP Trials with Components A, B, and C')\n",
    "plt.legend()\n",
    "\n",
    "# Set x-axis labels from 0 to duration, repeated for each trial\n",
    "xticks_single = np.linspace(0, duration, 10)\n",
    "plt.xticks(xticks_single * sampling_rate, [f'{xt:.1f}' for xt in xticks_single])\n",
    "plt.xlabel('Time (s)')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "stop_amplitudes = data_df['Stop amplitude'].dropna().to_numpy()\n",
    "ssds = data_df['SSD'].dropna().to_numpy()\n",
    "response_amplitudes = data_df[data_df['response_type'] == 'error']['Response amplitude'].to_numpy()\n",
    "sris = data_df['SRI'].dropna().to_numpy()\n",
    "\n",
    "\n",
    "print(f'Correlation between STOP amplitude and SSD distance: {pearsonr(stop_amplitudes, ssds)}')\n",
    "print(f'Correlation between RESPONSE amplitude and SRI distance: {pearsonr(response_amplitudes, sris)}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c711d42591a262e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot single-trials"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8e8a23e5df269f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set global font size for various elements\n",
    "plt.rcParams.update({\n",
    "    'font.size': 25,\n",
    "    'axes.titlesize': 30,\n",
    "    'axes.labelsize': 30,\n",
    "    'xtick.labelsize': 15,\n",
    "    'ytick.labelsize': 30,\n",
    "    'legend.fontsize': 25,\n",
    "    'figure.titlesize': 25,\n",
    "})\n",
    "\n",
    "raws = np.ravel(erp_trials)\n",
    "n_trials_to_plot = 2\n",
    "start = 10\n",
    "offset = int(duration * sampling_rate)\n",
    "\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.plot(raws[start*offset:(start+n_trials_to_plot)*offset])\n",
    "\n",
    "for i in np.arange(0, n_trials_to_plot):\n",
    "    go_latency = data_df.iloc[start+i]['Go event latency'] + i*offset\n",
    "    stop_latency = data_df.iloc[start+i]['Stop event latency'] + i*offset\n",
    "    response_latency = data_df.iloc[start+i]['Response event latency'] + i*offset\n",
    "\n",
    "    plt.axvline(x=go_latency, color=\"green\")\n",
    "    plt.axvline(x=stop_latency, color=\"red\")\n",
    "    plt.axvline(x=response_latency, color=\"blue\")\n",
    "\n",
    "    plt.axvline(x=i*offset, color=\"black\", linestyle='--')\n",
    "\n",
    "# Set x-axis labels from 0 to duration, repeated for each trial\n",
    "xticks_single = np.linspace(0, duration, 10)\n",
    "xticks_all_trials = np.concatenate([xticks_single + i * duration for i in range(n_trials_to_plot)])\n",
    "plt.xticks(xticks_all_trials * sampling_rate, [f'{xt:.1f}' for xt in np.tile(xticks_single, n_trials_to_plot)])\n",
    "plt.xlabel('Time (s)')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cf5690ce85d0487"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plor UN single trials"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0eb5b4960db6f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unsucc_data_df = data_df[data_df['response_type'] == 'error']\n",
    "unsucc_data_df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31a75f6f07b7651d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set global font size for various elements\n",
    "plt.rcParams.update({\n",
    "    'font.size': 25,\n",
    "    'axes.titlesize': 30,\n",
    "    'axes.labelsize': 30,\n",
    "    'xtick.labelsize': 15,\n",
    "    'ytick.labelsize': 30,\n",
    "    'legend.fontsize': 25,\n",
    "    'figure.titlesize': 25,\n",
    "})\n",
    "\n",
    "start = 0\n",
    "offset = int(duration * sampling_rate)\n",
    "\n",
    "data = np.concatenate(unsucc_data_df.iloc[start:start+n_trials_to_plot]['signal'].to_numpy())\n",
    "plt.figure(figsize=(16, 6), dpi=80)\n",
    "plt.plot(data)\n",
    "# \n",
    "for i in np.arange(0, n_trials_to_plot):\n",
    "    go_latency = unsucc_data_df.iloc[start+i]['Go event latency'] + i*offset\n",
    "    stop_latency = unsucc_data_df.iloc[start+i]['Stop event latency'] + i*offset\n",
    "    response_latency = unsucc_data_df.iloc[start+i]['Response event latency'] + i*offset\n",
    "\n",
    "    plt.axvline(x=go_latency, color=\"green\")\n",
    "    plt.axvline(x=stop_latency, color=\"red\")\n",
    "    plt.axvline(x=response_latency, color=\"blue\")\n",
    "\n",
    "    plt.axvline(x=i*offset, color=\"black\", linestyle='--')\n",
    "\n",
    "# Set x-axis labels from 0 to duration, repeated for each trial\n",
    "xticks_single = np.linspace(0, duration, 10)\n",
    "xticks_all_trials = np.concatenate([xticks_single + i * duration for i in range(n_trials_to_plot)])\n",
    "plt.xticks(xticks_all_trials * sampling_rate, [f'{xt:.1f}' for xt in np.tile(xticks_single, n_trials_to_plot)])\n",
    "plt.xlabel('Time (s)')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4440da788f4ea2f9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create events dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7643f7167085725"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "# Iterate through the input DataFrame and populate the list\n",
    "for idx, row in data_df.iterrows():\n",
    "    signal_offset = idx * int(duration*sampling_rate)\n",
    "\n",
    "    # Add each event to the list with the appropriate latency and event type\n",
    "    rows.append({\n",
    "        'latency': signal_offset + row['Go event latency'], \n",
    "        'event': 'go', \n",
    "        'SSD': row['SSD'] if pd.notna(row['Go event latency']) else np.nan, \n",
    "        'SRI': row['SRI'] if pd.notna(row['Go event latency']) else np.nan,\n",
    "        'response_type': row['response_type']\n",
    "    })\n",
    "\n",
    "    if pd.notna(row['Stop event latency']):\n",
    "        rows.append({\n",
    "            'latency': signal_offset + row['Stop event latency'],\n",
    "            'event': 'stop',\n",
    "            'SSD': row['SSD'],\n",
    "            'SRI': row['SRI'] if pd.notna(row['Response event latency']) else np.nan,\n",
    "            'response_type': row['response_type']\n",
    "        })\n",
    "        \n",
    "        if pd.notna(row['Response event latency']):\n",
    "            rows.append({\n",
    "                'latency': signal_offset + row['Response event latency'],\n",
    "                'event': 'response',\n",
    "                'SSD': row['SSD'],\n",
    "                'SRI': row['SRI'],\n",
    "                'response_type': row['response_type']\n",
    "            })\n",
    "    else:\n",
    "        rows.append({\n",
    "            'latency': signal_offset + row['Response event latency'],\n",
    "            'event': 'response_nostop',\n",
    "            'SSD': np.nan,\n",
    "            'SRI': np.nan,\n",
    "            'response_type': row['response_type']\n",
    "        })  \n",
    "\n",
    "# Create a new DataFrame from the list\n",
    "events_df = pd.DataFrame(rows)\n",
    "\n",
    "events_df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdd8d69fc16161e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "events_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1584b258681efe4d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Center continuous columns\n",
    "ssd_mean = np.nanmean(events_df['SSD'])\n",
    "events_df['ssd_centered'] = events_df['SSD'] - ssd_mean\n",
    "\n",
    "sri_mean = np.nanmean(events_df['SRI'])\n",
    "events_df['sri_centered'] = events_df['SRI'] - sri_mean"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d959ebf210186642"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perform unfolding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69870f2c3d742f7b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import the Julia package manager\n",
    "from juliacall import Pkg as jlPkg\n",
    "\n",
    "# Activate the environment in the current folder\n",
    "jlPkg.activate(\".\")\n",
    "\n",
    "# Check the status of the environment/installed packages -> will be empty at the beginning\n",
    "print(jlPkg.status())\n",
    "\n",
    "# Install Julia packages\n",
    "jlPkg.add(\"Unfold\")\n",
    "jlPkg.add(\"DataFrames\")\n",
    "jlPkg.add(url=\"https://github.com/unfoldtoolbox/UnfoldDecode.jl\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2eed552b93ec1123"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from juliacall import Main as jl\n",
    "\n",
    "# The function seval() can be used to evaluate a piece of Julia code given as a string\n",
    "jl.seval(\"using DataFrames\")\n",
    "jl.seval(\"using Unfold\")\n",
    "jl.seval(\"using UnfoldDecode\")\n",
    "Unfold = jl.Unfold\n",
    "UnfoldDecode = jl.UnfoldDecode"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86db9dfd6b51d7d0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Unfold model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d3e89c421e6cb74"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "events_df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7801f4dc125e1c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Specify model formula\n",
    "bf_go = jl.seval(\"bf_go = firbasis(τ = (-0.2, 0.5), sfreq = 64)\")\n",
    "bf_stop= jl.seval(\"bf_stop = firbasis(τ = (-0.2, 0.5), sfreq = 64)\")\n",
    "bf_response = jl.seval(\"bf_response = firbasis(τ = (-0.1, 0.6), sfreq = 64)\")\n",
    "bf_response_nostop = jl.seval(\"bf_response_nostop = firbasis(τ = (0-0.1, 0.6), sfreq = 64)\")\n",
    "\n",
    "formula_go = jl.seval(\"f_go = @formula 0 ~ 1\")\n",
    "formula_stop = jl.seval(\"f_stop = @formula 0 ~ 1 + ssd_centered\")\n",
    "formula_res = jl.seval(\"f_response = @formula 0 ~ 1 + sri_centered + ssd_centered\")\n",
    "formula_res_nostop = jl.seval(\"f_response_nostop = @formula 0 ~ 1\")\n",
    "\n",
    "\n",
    "bfDict = jl.seval(\"[ \\\"go\\\" => (f_go, bf_go), \\\"stop\\\" => (f_stop, bf_stop),  \\\"response\\\" => (f_response, bf_response), \\\"response_nostop\\\" => (f_response_nostop, bf_response_nostop)]\")\n",
    "\n",
    "# Convert the Python columns to Julia arrays\n",
    "type_column = jl.seval(\"Vector{String}\")(events_df['event'].tolist())\n",
    "response_type_column = jl.seval(\"Vector{String}\")(events_df['response_type'].tolist())\n",
    "ssd_centered_column = jl.seval(\"Vector{Float64}\")(events_df['ssd_centered'].tolist())\n",
    "sri_centered_column = jl.seval(\"Vector{Float64}\")(events_df['sri_centered'].tolist())\n",
    "latency_column = jl.seval(\"Vector{Int64}\")(events_df['latency'].tolist())\n",
    "\n",
    "# Create the Julia DataFrame\n",
    "events_df_jl = jl.DataFrame(\n",
    "    type=type_column, \n",
    "    latency=latency_column, \n",
    "    ssd_centered=ssd_centered_column, \n",
    "    sri_centered=sri_centered_column, \n",
    "    response_type=response_type_column\n",
    ")\n",
    "\n",
    "raws = np.ravel(erp_trials)\n",
    "\n",
    "# Fit Unfold model\n",
    "m = Unfold.fit(\n",
    "    Unfold.UnfoldModel,\n",
    "    bfDict,\n",
    "    events_df_jl,\n",
    "    raws,\n",
    "    eventcolumn = \"type\",\n",
    ")\n",
    "# model_matrix = Unfold.modelmatrix(m)\n",
    "# design_matrix = Unfold.designmatrix(m)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b8a3826cec71340"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff8924163e11f242"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def jl_results_to_python(results_jl):\n",
    "    results_py_df = pd.DataFrame({\n",
    "        'channel': results_jl.channel,\n",
    "        'coefname': results_jl.coefname,\n",
    "        'estimate': results_jl.estimate,\n",
    "        'eventname': results_jl.eventname,\n",
    "        'group': results_jl.group,\n",
    "        'stderror': results_jl.stderror,\n",
    "        'time': results_jl.time\n",
    "    })\n",
    "    return results_py_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae9d4a01bcc6c629"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_jl = Unfold.coeftable(m)\n",
    "results_py = jl_results_to_python(results_jl)\n",
    "results_py"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e5b3ee502893ab7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plot results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "127edc963324b9a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Extract the coefficients for one channel\n",
    "results_channel = results_py[results_py.channel == 1]\n",
    "\n",
    "results_go = results_channel[results_channel.eventname == 'go']\n",
    "results_stop = results_channel[results_channel.eventname == 'stop']\n",
    "results_response = results_channel[results_channel.eventname == 'response']\n",
    "results_response_nostop = results_channel[results_channel.eventname == 'response_nostop']\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Set global font size for various elements\n",
    "plt.rcParams.update({\n",
    "    'font.size': 25,          \n",
    "    'axes.titlesize': 30,     \n",
    "    'axes.labelsize': 30,    \n",
    "    'xtick.labelsize': 30,   \n",
    "    'ytick.labelsize': 30, \n",
    "    'legend.fontsize': 25, \n",
    "    'figure.titlesize': 25,\n",
    "})\n",
    "linewidth = 5\n",
    "# Plot the coefficient estimates over time\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(30, 20), sharey=True)\n",
    "\n",
    "ax1 = sns.lineplot(\n",
    "    x = results_go.time,\n",
    "    y=results_go.estimate,\n",
    "    hue=results_go.coefname,\n",
    "    ax=ax1,\n",
    "    linewidth=linewidth\n",
    ")\n",
    "ax1.set(xlabel='Time [s]', ylabel='Coefficient estimate', title='Go')\n",
    "\n",
    "ax2 = sns.lineplot(\n",
    "    x = results_stop.time,\n",
    "    y=results_stop.estimate,\n",
    "    hue=results_stop.coefname,\n",
    "    ax=ax2,\n",
    "    linewidth=linewidth\n",
    ")\n",
    "ax2.set(xlabel='Time [s]', ylabel='Coefficient estimate', title='Stop')\n",
    "\n",
    "ax3 = sns.lineplot(\n",
    "    x = results_response.time,\n",
    "    y=results_response.estimate,\n",
    "    hue=results_response.coefname,\n",
    "    ax=ax3,\n",
    "    linewidth=linewidth\n",
    ")\n",
    "ax3.set(xlabel='Time [s]', ylabel='Coefficient estimate', title='Response')\n",
    "\n",
    "ax4 = sns.lineplot(\n",
    "    x = results_response_nostop.time,\n",
    "    y=results_response_nostop.estimate,\n",
    "    hue=results_response_nostop.coefname,\n",
    "    ax=ax4,\n",
    "    linewidth=linewidth\n",
    ")\n",
    "ax4.set(xlabel='Time [s]', ylabel='Coefficient estimate', title='Response nostop')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "222fa94f179509ef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c0e9cbf1eef77a34"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "neuronoodle",
   "language": "python",
   "display_name": "neuroNoodle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
